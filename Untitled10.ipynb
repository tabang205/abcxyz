{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNWdGw2EpC+3uBhfDvkSoan",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tabang205/abcxyz/blob/main/Untitled10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Đọc dữ liệu\n",
        "df = pd.read_csv('loan_data.csv')\n",
        "\n",
        "# Làm sạch dữ liệu\n",
        "df = df[df['person_age'] <= 100]  # Loại bỏ tuổi bất thường\n",
        "df = df[df['person_emp_exp'] <= (df['person_age'] - 16)]  # Loại bỏ kinh nghiệm làm việc không hợp lý\n",
        "df = df.dropna()  # Loại bỏ giá trị thiếu\n",
        "\n",
        "# Phân chia đặc trưng và mục tiêu\n",
        "X = df.drop('loan_status', axis=1)\n",
        "y = df['loan_status']\n",
        "\n",
        "# Các cột danh mục và số\n",
        "categorical_cols = ['person_gender', 'person_education', 'person_home_ownership',\n",
        "                    'loan_intent', 'previous_loan_defaults_on_file']\n",
        "numerical_cols = ['person_age', 'person_income', 'person_emp_exp', 'loan_amnt',\n",
        "                 'loan_int_rate', 'loan_percent_income', 'cb_person_cred_hist_length',\n",
        "                 'credit_score']\n",
        "\n",
        "# Tạo preprocessor\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numerical_cols),\n",
        "        ('cat', OneHotEncoder(drop='first', sparse_output=False), categorical_cols)\n",
        "    ])\n",
        "\n",
        "# Chia dữ liệu\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Áp dụng preprocessor trước SMOTE\n",
        "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
        "X_test_preprocessed = preprocessor.transform(X_test)\n",
        "\n",
        "# Xử lý mất cân bằng lớp bằng SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_preprocessed, y_train)\n",
        "\n",
        "# Định nghĩa các mô hình\n",
        "models = {\n",
        "    'Logistic Regression': LogisticRegression(random_state=42, class_weight='balanced'),\n",
        "    'Naive Bayes': GaussianNB(),\n",
        "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
        "    'k-NN': KNeighborsClassifier()\n",
        "}\n",
        "\n",
        "# Huấn luyện và đánh giá mô hình\n",
        "results = {}\n",
        "for name, model in models.items():\n",
        "    # Huấn luyện mô hình trực tiếp trên dữ liệu đã tiền xử lý\n",
        "    model.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "    # Dự đoán\n",
        "    y_pred = model.predict(X_test_preprocessed)\n",
        "\n",
        "    # Đánh giá\n",
        "    report = classification_report(y_test, y_pred, output_dict=True)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    results[name] = {\n",
        "        'Accuracy': accuracy,\n",
        "        'Precision': report['1']['precision'],\n",
        "        'Recall': report['1']['recall'],\n",
        "        'F1-Score': report['1']['f1-score']\n",
        "    }\n",
        "\n",
        "    print(f\"\\nResults for {name}:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Tối ưu hóa Logistic Regression\n",
        "param_grid_lr = {\n",
        "    'C': [0.01, 0.1, 1, 10],\n",
        "    'solver': ['lbfgs', 'liblinear']\n",
        "}\n",
        "grid_search_lr = GridSearchCV(LogisticRegression(random_state=42, class_weight='balanced'),\n",
        "                              param_grid_lr, cv=5, scoring='f1', n_jobs=-1)\n",
        "grid_search_lr.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Kết quả Logistic Regression tốt nhất\n",
        "print(\"\\nBest Logistic Regression Parameters:\", grid_search_lr.best_params_)\n",
        "print(\"Best F1-Score:\", grid_search_lr.best_score_)\n",
        "\n",
        "# Tối ưu hóa Decision Tree\n",
        "param_grid_dt = {\n",
        "    'max_depth': [5, 10, 20, None],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "grid_search_dt = GridSearchCV(DecisionTreeClassifier(random_state=42),\n",
        "                              param_grid_dt, cv=5, scoring='f1', n_jobs=-1)\n",
        "grid_search_dt.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Kết quả Decision Tree tốt nhất\n",
        "print(\"\\nBest Decision Tree Parameters:\", grid_search_dt.best_params_)\n",
        "print(\"Best F1-Score:\", grid_search_dt.best_score_)\n",
        "\n",
        "# Tối ưu hóa k-NN\n",
        "param_grid_knn = {\n",
        "    'n_neighbors': [3, 5, 7, 10],\n",
        "    'weights': ['uniform', 'distance']\n",
        "}\n",
        "grid_search_knn = GridSearchCV(KNeighborsClassifier(),\n",
        "                               param_grid_knn, cv=5, scoring='f1', n_jobs=-1)\n",
        "grid_search_knn.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Kết quả k-NN tốt nhất\n",
        "print(\"\\nBest k-NN Parameters:\", grid_search_knn.best_params_)\n",
        "print(\"Best F1-Score:\", grid_search_knn.best_score_)\n",
        "\n",
        "# Phân tích đặc trưng quan trọng (Decision Tree)\n",
        "feature_names = numerical_cols + list(preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_cols))\n",
        "importances = grid_search_dt.best_estimator_.feature_importances_\n",
        "feature_importance = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
        "print(\"\\nFeature Importance (Decision Tree):\")\n",
        "print(feature_importance.sort_values(by='Importance', ascending=False).head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlljb312HCti",
        "outputId": "10410c97-6e10-4252-d697-3e74deef4b47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Results for Logistic Regression:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.84      0.90      6999\n",
            "           1       0.62      0.91      0.74      2000\n",
            "\n",
            "    accuracy                           0.85      8999\n",
            "   macro avg       0.79      0.87      0.82      8999\n",
            "weighted avg       0.89      0.85      0.86      8999\n",
            "\n",
            "Accuracy: 0.8547\n",
            "\n",
            "Results for Naive Bayes:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.69      0.81      6999\n",
            "           1       0.47      0.97      0.63      2000\n",
            "\n",
            "    accuracy                           0.75      8999\n",
            "   macro avg       0.73      0.83      0.72      8999\n",
            "weighted avg       0.87      0.75      0.77      8999\n",
            "\n",
            "Accuracy: 0.7501\n",
            "\n",
            "Results for Decision Tree:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.91      0.93      6999\n",
            "           1       0.72      0.80      0.76      2000\n",
            "\n",
            "    accuracy                           0.89      8999\n",
            "   macro avg       0.83      0.86      0.84      8999\n",
            "weighted avg       0.89      0.89      0.89      8999\n",
            "\n",
            "Accuracy: 0.8875\n",
            "\n",
            "Results for k-NN:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.85      0.90      6999\n",
            "           1       0.62      0.86      0.72      2000\n",
            "\n",
            "    accuracy                           0.85      8999\n",
            "   macro avg       0.79      0.85      0.81      8999\n",
            "weighted avg       0.88      0.85      0.86      8999\n",
            "\n",
            "Accuracy: 0.8502\n",
            "\n",
            "Best Logistic Regression Parameters: {'C': 1, 'solver': 'lbfgs'}\n",
            "Best F1-Score: 0.8916387069182223\n",
            "\n",
            "Best Decision Tree Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
            "Best F1-Score: 0.9170716602592434\n",
            "\n",
            "Best k-NN Parameters: {'n_neighbors': 3, 'weights': 'distance'}\n",
            "Best F1-Score: 0.92834483978789\n",
            "\n",
            "Feature Importance (Decision Tree):\n",
            "                               Feature  Importance\n",
            "21  previous_loan_defaults_on_file_Yes    0.484463\n",
            "4                        loan_int_rate    0.112255\n",
            "1                        person_income    0.074825\n",
            "15          person_home_ownership_RENT    0.073444\n",
            "5                  loan_percent_income    0.055770\n",
            "7                         credit_score    0.039001\n",
            "0                           person_age    0.023909\n",
            "6           cb_person_cred_hist_length    0.022796\n",
            "3                            loan_amnt    0.022183\n",
            "2                       person_emp_exp    0.021110\n"
          ]
        }
      ]
    }
  ]
}